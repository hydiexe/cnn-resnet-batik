{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11681012,"sourceType":"datasetVersion","datasetId":7331284}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport copy\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:31.970591Z","iopub.execute_input":"2025-05-05T09:55:31.971107Z","iopub.status.idle":"2025-05-05T09:55:40.231988Z","shell.execute_reply.started":"2025-05-05T09:55:31.971086Z","shell.execute_reply":"2025-05-05T09:55:40.231225Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# config\nDATA_DIR = '/kaggle/input/dataset-batik-indonesia'\nTRAIN_DIR = os.path.join(DATA_DIR, 'preprocessing_images')\nVAL_DIR = os.path.join(DATA_DIR, 'dataset_split/val')\nTEST_DIR = os.path.join(DATA_DIR, 'dataset_split/test')\n\nOUTPUT_DIR = './batik_results'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nBATCH_SIZE = 32\nNUM_EPOCHS = 50\nLR = 0.001\nPATIENCE = 5\nMODEL_NAMES = [\n    'resnet18', 'resnet34', 'resnet50',\n    'resnet101', 'resnet152', 'resnet110'\n]\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:40.233417Z","iopub.execute_input":"2025-05-05T09:55:40.233842Z","iopub.status.idle":"2025-05-05T09:55:40.323720Z","shell.execute_reply.started":"2025-05-05T09:55:40.233816Z","shell.execute_reply":"2025-05-05T09:55:40.322800Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# data transform\nbasic_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:40.324521Z","iopub.execute_input":"2025-05-05T09:55:40.324744Z","iopub.status.idle":"2025-05-05T09:55:40.347599Z","shell.execute_reply.started":"2025-05-05T09:55:40.324719Z","shell.execute_reply":"2025-05-05T09:55:40.347093Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# data loaders\ndef get_loaders(train_dir, val_dir, test_dir, batch_size):\n    image_datasets = {\n        'train': datasets.ImageFolder(train_dir, basic_transforms),\n        'val': datasets.ImageFolder(val_dir, basic_transforms),\n        'test': datasets.ImageFolder(test_dir, basic_transforms)\n    }\n    dataloaders = {\n        x: DataLoader(image_datasets[x], batch_size=batch_size,\n                      shuffle=(x == 'train'), num_workers=2)\n        for x in ['train', 'val', 'test']\n    }\n    return dataloaders, image_datasets['train'].classes\n\nloaders, class_names = get_loaders(TRAIN_DIR, VAL_DIR, TEST_DIR, BATCH_SIZE)\nNUM_CLASSES = len(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:40.348945Z","iopub.execute_input":"2025-05-05T09:55:40.349216Z","iopub.status.idle":"2025-05-05T09:55:58.301144Z","shell.execute_reply.started":"2025-05-05T09:55:40.349200Z","shell.execute_reply":"2025-05-05T09:55:58.300558Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# init model\nfrom torchvision.models.resnet import ResNet, BasicBlock\n\ndef initialize_model(name, num_classes, pretrained=True):\n    if name == 'resnet18': model = models.resnet18(pretrained=pretrained)\n    elif name == 'resnet34': model = models.resnet34(pretrained=pretrained)\n    elif name == 'resnet50': model = models.resnet50(pretrained=pretrained)\n    elif name == 'resnet101': model = models.resnet101(pretrained=pretrained)\n    elif name == 'resnet152': model = models.resnet152(pretrained=pretrained)\n    elif name == 'resnet110':  # Custom ResNet-110\n        model = ResNet(BasicBlock, [18, 18, 18], num_classes=num_classes)\n    else:\n        raise ValueError(f\"Unknown model {name}\")\n\n    if hasattr(model, 'fc'):\n        in_features = model.fc.in_features\n        model.fc = nn.Linear(in_features, num_classes)\n\n    return model.to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:58.301854Z","iopub.execute_input":"2025-05-05T09:55:58.302039Z","iopub.status.idle":"2025-05-05T09:55:58.308247Z","shell.execute_reply.started":"2025-05-05T09:55:58.302024Z","shell.execute_reply":"2025-05-05T09:55:58.307461Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# training\ndef train_model(model, dataloaders, criterion, optimizer, num_epochs, patience):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n    counter = 0\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        for phase in ['train', 'val']:\n            model.train() if phase == 'train' else model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    preds = outputs.argmax(dim=1)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels)\n\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            history[f\"{phase}_loss\"].append(epoch_loss)\n            history[f\"{phase}_acc\"].append(epoch_acc.item())\n\n            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n\n            # early stopping check\n            if phase == 'val':\n                if epoch_acc > best_acc:\n                    best_acc = epoch_acc\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                    counter = 0\n                else:\n                    counter += 1\n                    if counter >= patience:\n                        print(\"Early stopping.\")\n                        model.load_state_dict(best_model_wts)\n                        return model, history, best_acc.item()\n    model.load_state_dict(best_model_wts)\n    return model, history, best_acc.item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:58.309170Z","iopub.execute_input":"2025-05-05T09:55:58.309779Z","iopub.status.idle":"2025-05-05T09:55:58.366207Z","shell.execute_reply.started":"2025-05-05T09:55:58.309753Z","shell.execute_reply":"2025-05-05T09:55:58.365373Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# evaluation\ndef evaluate_model(model, dataloader):\n    model.eval()\n    preds_all, labels_all = [], []\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs = inputs.to(DEVICE)\n            outputs = model(inputs)\n            preds = outputs.argmax(dim=1).cpu().numpy()\n            preds_all.extend(preds)\n            labels_all.extend(labels.numpy())\n    return (\n        accuracy_score(labels_all, preds_all),\n        precision_score(labels_all, preds_all, average='macro'),\n        recall_score(labels_all, preds_all, average='macro'),\n        f1_score(labels_all, preds_all, average='macro'),\n        confusion_matrix(labels_all, preds_all)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:58.366972Z","iopub.execute_input":"2025-05-05T09:55:58.367168Z","iopub.status.idle":"2025-05-05T09:55:58.385144Z","shell.execute_reply.started":"2025-05-05T09:55:58.367152Z","shell.execute_reply":"2025-05-05T09:55:58.384543Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# plotting\ndef plot_history(history, model_name):\n    epochs = range(1, len(history['train_loss']) + 1)\n    plt.figure()\n    plt.plot(epochs, history['train_loss'], label='Train Loss')\n    plt.plot(epochs, history['val_loss'], label='Val Loss')\n    plt.title(f'{model_name} - Loss')\n    plt.legend()\n    plt.savefig(os.path.join(OUTPUT_DIR, f'{model_name}_loss.png'))\n    plt.close()\n\n    plt.figure()\n    plt.plot(epochs, history['train_acc'], label='Train Acc')\n    plt.plot(epochs, history['val_acc'], label='Val Acc')\n    plt.title(f'{model_name} - Accuracy')\n    plt.legend()\n    plt.savefig(os.path.join(OUTPUT_DIR, f'{model_name}_acc.png'))\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:58.385902Z","iopub.execute_input":"2025-05-05T09:55:58.386171Z","iopub.status.idle":"2025-05-05T09:55:58.401202Z","shell.execute_reply.started":"2025-05-05T09:55:58.386141Z","shell.execute_reply":"2025-05-05T09:55:58.400468Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# main\nresults = []\nbest_model_name = ''\nbest_overall_acc = 0.0\nfor model_name in MODEL_NAMES:\n    print(f\"\\n--- Training {model_name} ---\")\n    model = initialize_model(model_name, NUM_CLASSES)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=LR)\n\n    trained_model, hist, val_acc = train_model(model, loaders, criterion, optimizer, NUM_EPOCHS, PATIENCE)\n    acc, prec, rec, f1, cm = evaluate_model(trained_model, loaders['test'])\n\n    torch.save(trained_model.state_dict(), os.path.join(OUTPUT_DIR, f\"{model_name}.pth\"))\n\n    results.append({\n        'Model': model_name,\n        'Val Accuracy': val_acc,\n        'Test Accuracy': acc,\n        'Precision': prec,\n        'Recall': rec,\n        'F1': f1\n    })\n\n    if val_acc > best_overall_acc:\n        best_overall_acc = val_acc\n        best_model_name = model_name\n\n    plot_history(hist, model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T09:55:58.402062Z","iopub.execute_input":"2025-05-05T09:55:58.402381Z"}},"outputs":[{"name":"stdout","text":"\n--- Training resnet18 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 181MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\ntrain Loss: 1.3787 Acc: 0.6017\nval Loss: 1.5955 Acc: 0.5833\nEpoch 2/50\ntrain Loss: 0.7239 Acc: 0.7817\nval Loss: 1.3280 Acc: 0.6667\nEpoch 3/50\ntrain Loss: 0.4272 Acc: 0.8643\nval Loss: 1.1391 Acc: 0.7067\nEpoch 4/50\ntrain Loss: 0.3504 Acc: 0.8928\nval Loss: 1.0256 Acc: 0.7367\nEpoch 5/50\ntrain Loss: 0.2266 Acc: 0.9296\nval Loss: 1.4441 Acc: 0.6633\nEpoch 6/50\ntrain Loss: 0.2704 Acc: 0.9127\nval Loss: 1.0903 Acc: 0.7167\nEpoch 7/50\ntrain Loss: 0.1806 Acc: 0.9469\nval Loss: 0.8693 Acc: 0.8033\nEpoch 8/50\ntrain Loss: 0.0840 Acc: 0.9734\nval Loss: 1.0181 Acc: 0.8033\nEpoch 9/50\ntrain Loss: 0.1524 Acc: 0.9532\nval Loss: 1.6451 Acc: 0.7400\nEpoch 10/50\ntrain Loss: 0.1206 Acc: 0.9638\nval Loss: 1.1651 Acc: 0.7767\nEpoch 11/50\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# save summary\ndf = pd.DataFrame(results)\ndf.to_csv(os.path.join(OUTPUT_DIR, 'summary.csv'), index=False)\nprint(\"\\nBest Model:\", best_model_name)\nprint(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}